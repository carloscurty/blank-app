import streamlit as st
import pandas as pd
import plotly.express as px
from sqlalchemy import create_engine, text
import urllib.parse
from datetime import date, timedelta

st.set_page_config(page_title="Takeat BI", layout="wide", page_icon="ü•ó")

# ==========================================================
# üõ†Ô∏è FUN√á√ïES DE FORMATA√á√ÉO E AJUDA
# ==========================================================
def formatar_real(valor):
    if pd.isna(valor): return "R$ 0,00"
    return f"R$ {valor:,.2f}".replace(',', 'X').replace('.', ',').replace('X', '.')

def traduzir_dia(data):
    dias = {
        'Monday': 'Seg', 'Tuesday': 'Ter', 'Wednesday': 'Qua', 
        'Thursday': 'Qui', 'Friday': 'Sex', 'Saturday': 'S√°b', 'Sunday': 'Dom'
    }
    return dias.get(data.strftime('%A'), '')

# ==========================================================
# üîó CONFIGURA√á√ÉO DE CONEX√ÉO
# ==========================================================
DB_HOST = "aws-1-us-east-2.pooler.supabase.com"
DB_PORT = "6543"
DB_NAME = "postgres"
DB_USER = "postgres.wnjmldfbjwfvkybessqg"
DB_PASS = "projetovendas2024"

try:
    senha_safe = urllib.parse.quote_plus(DB_PASS)
    DB_URI = f"postgresql+pg8000://{DB_USER}:{senha_safe}@{DB_HOST}:{DB_PORT}/{DB_NAME}"
except Exception as e:
    st.error(f"Erro de config: {e}")
    DB_URI = None

@st.cache_resource
def get_engine():
    return create_engine(DB_URI, pool_pre_ping=True)

@st.cache_data(ttl=0) 
def carregar_dados(query, params=None):
    engine = get_engine()
    with engine.connect() as conn:
        return pd.read_sql(text(query), conn, params=params)

# ==========================================================
# üß≠ NAVEGA√á√ÉO
# ==========================================================
st.sidebar.title("Navega√ß√£o")
pagina = st.sidebar.radio("Ir para:", ["üìä Dashboard", "‚öôÔ∏è Atualizar Dados"])
st.sidebar.divider()

if DB_URI is None: st.stop()

# ==========================================================
# P√ÅGINA 1: DASHBOARD COMPLETO E FORMATADO
# ==========================================================
if pagina == "üìä Dashboard":
    st.markdown("### ü•ó Dashboard de Vendas")
    try:
        # Pega limites de data
        df_datas = carregar_dados("SELECT MIN(data_hora) as data_min, MAX(data_hora) as data_max FROM vendas")
        if df_datas.empty or pd.isna(df_datas['data_min'][0]):
            st.info("Banco de dados vazio. V√° em 'Atualizar Dados' para come√ßar.")
            st.stop()
        
        min_db = pd.to_datetime(df_datas['data_min'][0]).date()
        max_db = pd.to_datetime(df_datas['data_max'][0]).date()
        
        # Filtros
        padrao_inicio = max_db - timedelta(days=30) if max_db - min_db > timedelta(days=30) else min_db
        st.sidebar.header("Filtros")
        intervalo = st.sidebar.date_input("Per√≠odo", (padrao_inicio, max_db), min_value=min_db, max_value=max_db, format="DD/MM/YYYY")

        if len(intervalo) == 2:
            data_ini, data_fim = intervalo
            
            # Tenta buscar 'metodo'. Se falhar (coluna n√£o existe), usa fallback.
            try:
                query = """
                    SELECT id_pedido, data_hora, canal_venda, valor_bruto, valor_liquido, metodo 
                    FROM vendas 
                    WHERE data_hora::date BETWEEN :d_ini AND :d_fim
                """
                df = carregar_dados(query, params={'d_ini': data_ini, 'd_fim': data_fim})
            except Exception:
                # Fallback silencioso ou com aviso discreto
                query_fallback = """
                    SELECT id_pedido, data_hora, canal_venda, valor_bruto, valor_liquido 
                    FROM vendas 
                    WHERE data_hora::date BETWEEN :d_ini AND :d_fim
                """
                df = carregar_dados(query_fallback, params={'d_ini': data_ini, 'd_fim': data_fim})
                df['metodo'] = 'N/D'

            
            if not df.empty:
                df['data_hora'] = pd.to_datetime(df['data_hora'])
                
                # --- 1. CARDS SUPERIORES ---
                k1, k2, k3, k4 = st.columns(4)
                fat = df['valor_bruto'].sum()
                ped = df['id_pedido'].nunique()
                liq = df['valor_liquido'].sum()
                
                k1.metric("Venda Bruta", formatar_real(fat))
                k2.metric("Ticket M√©dio", formatar_real(fat/ped if ped else 0))
                k3.metric("Venda L√≠quida", formatar_real(liq))
                k4.metric("Qtd. Pedidos", ped)
                st.divider()

                # --- 2. GR√ÅFICOS DE CANAL ---
                canal_stats = df.groupby('canal_venda').agg(
                    Faturamento=('valor_bruto', 'sum'),
                    Pedidos=('id_pedido', 'nunique')
                ).reset_index().sort_values('Faturamento', ascending=True)

                canal_stats['Faturamento_Label'] = canal_stats['Faturamento'].apply(formatar_real)

                g1, g2 = st.columns(2)
                
                with g1:
                    fig_pizza = px.pie(
                        canal_stats, 
                        values='Faturamento', 
                        names='canal_venda', 
                        title='Participa√ß√£o por Canal (%)',
                        hole=0.4
                    )
                    fig_pizza.update_traces(
                        textinfo='percent+label',
                        hovertemplate='<b>%{label}</b><br>Faturamento: %{value:,.2f}<extra></extra>'
                    )
                    st.plotly_chart(fig_pizza, use_container_width=True)

                with g2:
                    fig_bar = px.bar(
                        canal_stats, 
                        x='Faturamento', 
                        y='canal_venda', 
                        orientation='h', 
                        text='Faturamento_Label', 
                        title='Faturamento Total por Canal'
                    )
                    fig_bar.update_traces(
                        texttemplate='%{text}', 
                        textposition='outside',
                        hovertemplate='<b>%{y}</b><br>Total: %{text}<extra></extra>'
                    )
                    fig_bar.update_layout(xaxis_title="", yaxis_title="")
                    st.plotly_chart(fig_bar, use_container_width=True)

                # --- 3. EVOLU√á√ÉO DI√ÅRIA ---
                st.subheader("Evolu√ß√£o Di√°ria")
                
                diario = df.groupby(df['data_hora'].dt.date)['valor_bruto'].sum().reset_index()
                diario.columns = ['Data', 'Venda']
                diario['Data'] = pd.to_datetime(diario['Data'])
                diario = diario.sort_values('Data')

                media_periodo = diario['Venda'].mean()
                diario['Performance'] = diario['Venda'].apply(
                    lambda x: 'Acima da M√©dia' if x >= media_periodo else 'Abaixo da M√©dia'
                )
                
                diario['Data_Formatada'] = diario['Data'].apply(lambda x: f"{x.day:02d}/{x.month:02d}")
                diario['Venda_Label'] = diario['Venda'].apply(formatar_real)
                ordem_cronologica = diario['Data_Formatada'].tolist()

                fig_d = px.bar(
                    diario, 
                    x='Data_Formatada', 
                    y='Venda',
                    color='Performance',
                    color_discrete_map={'Acima da M√©dia': '#2ecc71', 'Abaixo da M√©dia': '#e74c3c'},
                    title="Vendas por Dia",
                    text='Venda_Label'
                )
                fig_d.update_layout(
                    xaxis=dict(title="", type='category', categoryorder='array', categoryarray=ordem_cronologica),
                    yaxis_title=None, yaxis_showticklabels=False, separators=",.", legend_title_text="",
                    legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
                )
                fig_d.update_traces(textposition='none', hovertemplate='<b>%{x}</b><br>Venda: %{text}<extra></extra>')
                st.plotly_chart(fig_d, use_container_width=True)

# --- 4. TABELA CRUZADA (M√âTODO x CANAL) ---
                st.divider()
                st.subheader("üìä Detalhamento: M√©todo x Canal")
                
                # --- √ÅREA DE DIAGN√ìSTICO E CORRE√á√ÉO ---
                if not df.empty and 'metodo' in df.columns and 'canal_venda' in df.columns:
                    
                    # 1. Tratamento de Choque (Limpeza For√ßada)
                    df['valor_bruto'] = pd.to_numeric(df['valor_bruto'], errors='coerce').fillna(0)
                    
                    # Preenche vazios para n√£o quebrar o pivot
                    df['metodo'] = df['metodo'].fillna('N√£o Identificado').astype(str)
                    df['canal_venda'] = df['canal_venda'].fillna('N√£o Identificado').astype(str)
                    
                    # Remove espa√ßos em branco
                    df['metodo'] = df['metodo'].str.strip()
                    df['canal_venda'] = df['canal_venda'].str.strip()

                    try:
                        # 2. Cria√ß√£o da Pivot Table
                        df_pivot = df.pivot_table(
                            index='metodo', 
                            columns='canal_venda', 
                            values='valor_bruto', 
                            aggfunc='sum', 
                            fill_value=0,
                            margins=True,          
                            margins_name='Total'   
                        )

                        # 3. Exibi√ß√£o
                        if df_pivot.empty or df_pivot.shape[0] == 0:
                            st.warning("‚ö†Ô∏è A tabela continua vazia mesmo ap√≥s limpeza.")
                        else:
                            # L√≥gica de Ordena√ß√£o
                            if 'Total' in df_pivot.columns and 'Total' in df_pivot.index:
                                linha_total = df_pivot.loc[['Total']]
                                df_resto = df_pivot.drop('Total', axis=0).sort_values('Total', ascending=False)
                                df_pivot_final = pd.concat([df_resto, linha_total])
                            else:
                                df_pivot_final = df_pivot

                            # --- CORRE√á√ÉO AQUI: Removemos o background_gradient que causava o erro ---
                            st.dataframe(
                                df_pivot_final.style.format("R$ {:,.2f}"), 
                                use_container_width=True
                            )
                            
                    except Exception as e:
                        st.error(f"Erro na gera√ß√£o da matriz: {e}")
                    
                    # 4. Bot√£o para DEBUG
                    with st.expander("üïµÔ∏è‚Äç‚ôÇÔ∏è Espiar dados brutos (Debug)"):
                        st.write("Abaixo, as primeiras 5 linhas usadas para tentar montar a tabela:")
                        st.dataframe(df[['data_hora', 'metodo', 'canal_venda', 'valor_bruto']].head())
                        st.write(f"Total de linhas carregadas: {len(df)}")
                else:
                    st.error("Colunas fundamentais ('metodo', 'canal_venda') n√£o encontradas no DataFrame.")

                # --- 5. CARDS INFERIORES ---
                st.markdown("##### Estat√≠sticas do Per√≠odo")
                s1, s2, s3 = st.columns(3)
                
                melhor_dia = diario['Venda'].max()
                pior_dia = diario['Venda'].min()
                dia_melhor_obj = diario.loc[diario['Venda'] == melhor_dia, 'Data'].values[0] if not diario.empty else None
                dia_pior_obj = diario.loc[diario['Venda'] == pior_dia, 'Data'].values[0] if not diario.empty else None
                
                label_melhor = f"{pd.to_datetime(dia_melhor_obj).strftime('%d/%m')} ({traduzir_dia(pd.to_datetime(dia_melhor_obj))})" if dia_melhor_obj else "-"
                label_pior = f"{pd.to_datetime(dia_pior_obj).strftime('%d/%m')} ({traduzir_dia(pd.to_datetime(dia_pior_obj))})" if dia_pior_obj else "-"

                s1.metric("M√©dia Di√°ria", formatar_real(media_periodo))
                s2.metric(f"Melhor Dia: {label_melhor}", formatar_real(melhor_dia))
                s3.metric(f"Pior Dia: {label_pior}", formatar_real(pior_dia))

            else:
                st.warning("Sem dados para o per√≠odo selecionado.")
    except Exception as e:
        st.error(f"Erro no Dashboard: {e}")
        st.cache_resource.clear()

# ==========================================================
# P√ÅGINA 2: CARGA COM SUBSTITUI√á√ÉO E CORRE√á√ÉO DE CHUNK
# ==========================================================
elif pagina == "‚öôÔ∏è Atualizar Dados":
    st.markdown("### ‚öôÔ∏è Atualiza√ß√£o e Corre√ß√£o")
    st.info("Utilize esta aba para carregar novos arquivos ou corrigir meses com dados errados.")
    
    arquivo = st.file_uploader("Arraste seu arquivo aqui (Excel ou CSV)", type=["xlsx", "csv", "xls"])
    substituir = st.checkbox("‚ö†Ô∏è Modo de Corre√ß√£o: Substituir dados existentes (Marque se precisar re-upar um m√™s com erro)")

    if arquivo and st.button("Processar e Salvar"):
        try:
            if arquivo.name.endswith('.csv'):
                df_temp = pd.read_csv(arquivo, header=None, nrows=10)
            else:
                df_temp = pd.read_excel(arquivo, header=None, nrows=10)

            idx_cabecalho = -1
            for i, row in df_temp.iterrows():
                if row.astype(str).str.contains("Pedido", case=False).any():
                    idx_cabecalho = i
                    break
            
            if idx_cabecalho == -1:
                st.error("‚ùå Coluna 'Pedido' n√£o encontrada no arquivo.")
                st.stop()

            arquivo.seek(0)
            if arquivo.name.endswith('.csv'):
                df_novo = pd.read_csv(arquivo, header=idx_cabecalho)
            else:
                df_novo = pd.read_excel(arquivo, header=idx_cabecalho)

            mapa_colunas = {
                'Pedido': 'id_pedido',
                'Data - Hora': 'data_hora',
                'Canal': 'canal_venda',
                'Valor Bruto': 'valor_bruto',
                'Valor L√≠quido': 'valor_liquido',
                'M√©todo': 'metodo'
            }
            
            df_novo = df_novo.rename(columns=mapa_colunas)
            colunas_validas = [c for c in mapa_colunas.values() if c in df_novo.columns]
            
            if 'id_pedido' not in colunas_validas:
                st.error("Erro Cr√≠tico: Coluna de ID do Pedido n√£o identificada.")
                st.stop()
                
            df_limpo = df_novo[colunas_validas].copy()
            
            if 'data_hora' in df_limpo.columns:
                df_limpo['data_hora'] = pd.to_datetime(df_limpo['data_hora'], format='%d/%m/%Y - %H:%M', errors='coerce')
                df_limpo = df_limpo.dropna(subset=['data_hora'])

            df_limpo['id_pedido'] = pd.to_numeric(df_limpo['id_pedido'], errors='coerce')
            df_limpo = df_limpo.dropna(subset=['id_pedido'])
            df_limpo['id_pedido'] = df_limpo['id_pedido'].astype('int64')

            if 'canal_venda' in df_limpo.columns:
                df_limpo['canal_venda'] = df_limpo['canal_venda'].fillna('Indefinido').astype(str)
            if 'metodo' in df_limpo.columns:
                df_limpo['metodo'] = df_limpo['metodo'].fillna('Outros').astype(str)
            else:
                df_limpo['metodo'] = 'N/D'

            if 'valor_bruto' in df_limpo.columns:
                df_limpo['valor_bruto'] = df_limpo['valor_bruto'].fillna(0.0)
            if 'valor_liquido' in df_limpo.columns:
                df_limpo['valor_liquido'] = df_limpo['valor_liquido'].fillna(0.0)

            aggs = {
                'data_hora': 'first',      
                'canal_venda': 'first',    
                'valor_bruto': 'sum',      
                'valor_liquido': 'sum'
            }
            if 'metodo' in df_limpo.columns:
                aggs['metodo'] = 'first'

            df_agrupado = df_limpo.groupby('id_pedido', as_index=False).agg(aggs)
            
            engine = get_engine()
            df_para_subir = pd.DataFrame()
            ids_no_arquivo = df_agrupado['id_pedido'].tolist()
            
            if substituir:
                st.info("üîÑ Modo de Corre√ß√£o Ativado. Substituindo registros...")
                with engine.begin() as conn:
                    if ids_no_arquivo:
                        ids_str = [str(x) for x in ids_no_arquivo]
                        chunk_size = 200 
                        for i in range(0, len(ids_str), chunk_size):
                            batch = tuple(ids_str[i:i + chunk_size])
                            if batch:
                                conn.execute(text(f"DELETE FROM vendas WHERE id_pedido::text IN {batch}"))
                df_para_subir = df_agrupado
            else:
                with engine.connect() as conn:
                    ids_banco = pd.read_sql(text("SELECT id_pedido FROM vendas"), conn)
                lista_existentes = set(ids_banco['id_pedido'].astype('int64').tolist())
                df_para_subir = df_agrupado[~df_agrupado['id_pedido'].isin(lista_existentes)]

            qtd = len(df_para_subir)
            
            if qtd > 0:
                progresso = st.progress(0)
                st.write(f"Gravando {qtd} registros em lotes menores...")
                
                with engine.begin() as conn:
                    df_para_subir.to_sql('vendas', conn, if_exists='append', index=False, chunksize=200)
                
                progresso.progress(100)
                st.success("‚úÖ Processo conclu√≠do com sucesso!")
                st.balloons()
                st.cache_data.clear()
            else:
                st.warning("‚ö†Ô∏è Arquivo processado. Nenhuma venda nova encontrada.")

        except Exception as e:
            st.error(f"Erro detalhado: {e}")
            st.cache_resource.clear()